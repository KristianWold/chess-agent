{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu128\n",
      "CUDA toolkit version PyTorch was built with: 12.8\n",
      "cuDNN version: 90701\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import config\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import copy, deepcopy\n",
    "import cmath\n",
    "import chess\n",
    "from utils import saver, loader\n",
    "\n",
    "from agents import *\n",
    "from environments import *\n",
    "from models import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision = 3)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)  \n",
    "print(\"CUDA toolkit version PyTorch was built with:\", torch.version.cuda)  \n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version()) \n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2984908\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "agent = Agent(board_logic = BoardLogic(max_num_moves=100), \n",
    "              in_ch=18, \n",
    "              ch=128, \n",
    "              n_blocks=10)\n",
    "\n",
    "print(sum(p.numel() for p in agent.online_net1.parameters() if p.requires_grad))\n",
    "environment = Environment(max_num_moves=100,\n",
    "                          filter_blunder=False, # causes a lot of draw in early self-play of on\n",
    "                          )\n",
    "\n",
    "opt_list = [None, None]\n",
    "\n",
    "model = Model(agent = agent,\n",
    "               environment = environment,\n",
    "               mem_capacity = 1000000,\n",
    "               init_mem = False,\n",
    "               batch_size = 512,\n",
    "               num_warmup = 100000,\n",
    "               policy_update = 2,\n",
    "               tau = 0.01,\n",
    "               temp_scaler = TemperatureScaler(temp_start=0.6, \n",
    "                                               temp_end=0.2, \n",
    "                                               temp_min=1e-5, \n",
    "                                               episode_decay=5000, \n",
    "                                               transition_decay=0.95),\n",
    "               opt_list=opt_list,\n",
    "               scaler=torch.amp.GradScaler(\"cuda\")\n",
    "             )\n",
    "\n",
    "optimizer_grouped_parameters1 = group_decay_parameters(\n",
    "    agent.online_net1,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "optimizer_grouped_parameters2 = group_decay_parameters(\n",
    "    agent.online_net2,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "opt_list[0] = torch.optim.AdamW(optimizer_grouped_parameters1, lr=1e-4)\n",
    "opt_list[1] = torch.optim.AdamW(optimizer_grouped_parameters2, lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=100, \n",
    "                                                       filter_blunder=False), \n",
    "                             num_games=500,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_core(model, filename=\"model_conv_5000_episodes_core.pth\")\n",
    "save_memory(model, filename=\"model_conv_5000_episodes_memory.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=100, \n",
    "                                                       filter_blunder=False), \n",
    "                             num_games=500,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=500)\n",
    "\n",
    "save_core(model, filename=\"model_conv_10000_episodes_core.pth\")\n",
    "save_memory(model, filename=\"model_conv_10000_episodes_memory.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint(core_path=\"model_conv_10000_episodes_core.pth\",\n",
    "                        memory_path=\"model_conv_10000_episodes_memory.pth\",\n",
    "                        model = model)\n",
    "\n",
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=100, \n",
    "                                                       filter_blunder=False), \n",
    "                             num_games=500,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_core(model, filename=\"model_conv_15000_episodes_core.pth\")\n",
    "save_memory(model, filename=\"model_conv_15000_episodes_memory.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=100, \n",
    "                                                       filter_blunder=False), \n",
    "                             num_games=500,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_core(model, filename=\"model_conv_20000_episodes_core.pth\")\n",
    "save_memory(model, filename=\"model_conv_20000_episodes_memory.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=100, \n",
    "                                                       filter_blunder=False), \n",
    "                             num_games=500,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_core(model, filename=\"model_conv_25000_episodes_core.pth\")\n",
    "save_memory(model, filename=\"model_conv_25000_episodes_memory.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint(core_path=\"model_conv_25000_episodes_core.pth\",\n",
    "                        memory_path=\"model_conv_25000_episodes_memory.pth\",\n",
    "                        model = model)\n",
    "\n",
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=100, \n",
    "                                                       filter_blunder=False), \n",
    "                             num_games=500,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_core(model, filename=\"model_conv_30000_episodes_core.pth\")\n",
    "save_memory(model, filename=\"model_conv_30000_episodes_memory.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8357d5654df74327b38e5f1752bc2a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5897e350005a4da8af06349f961ea681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 163, -1: 175, 0: 162} 0 0.07016114427480759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124dd7a5736f498abcad6850c47d9104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 171, -1: 180, 0: 149} tensor(0.0005, device='cuda:0') 0.07321388461061686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598940b26b274195bef312ce0e87e1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 194, -1: 173, 0: 133} tensor(0.0006, device='cuda:0') 0.06667578115045805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c92953071645219490524a8c68324f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 169, -1: 192, 0: 139} tensor(0.0004, device='cuda:0') 0.0669390497354827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd5306dedf2473f96ff9db5f8acc2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 189, -1: 152, 0: 159} tensor(0.0005, device='cuda:0') 0.06887233911315435\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = load_checkpoint(core_path=\"model_conv_30000_episodes_core.pth\",\n",
    "                        memory_path=\"model_conv_30000_episodes_memory.pth\",\n",
    "                        model = model)\n",
    "\n",
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=100, \n",
    "                                                       filter_blunder=False), \n",
    "                             num_games=500,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_core(model, filename=\"model_conv_35000_episodes_core.pth\")\n",
    "save_memory(model, filename=\"model_conv_35000_episodes_memory.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7525cc8cf8a4cf6abd81de201481c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abfd938e2a240bcb66588f7d3c5571f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 176, -1: 195, 0: 129} 0 0.0747083069473578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1652151099834b0fb4e4daae488ceef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 173, -1: 179, 0: 148} tensor(0.0005, device='cuda:0') 0.06817331567826662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b105c995edb24f4ba9358b274c58fd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 185, -1: 175, 0: 140} tensor(0.0004, device='cuda:0') 0.06968849941572149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae76640803cf464d824102f72bfa503b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 177, -1: 191, 0: 132} tensor(0.0006, device='cuda:0') 0.06522818079207268\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint(core_path=\"model_conv_35000_episodes_core.pth\",\n",
    "                        memory_path=\"model_conv_35000_episodes_memory.pth\",\n",
    "                        model = model)\n",
    "\n",
    "\n",
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=100, \n",
    "                                                       filter_blunder=False), \n",
    "                             num_games=500,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_core(model, filename=\"model_conv_40000_episodes_core.pth\")\n",
    "save_memory(model, filename=\"model_conv_40000_episodes_memory.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint(\"model_conv_35000_episodes_large.pth\", model)\n",
    "agent1 = deepcopy(model.agent)\n",
    "model = load_checkpoint(\"model_conv_35000_episodes_large.pth\", model)\n",
    "agent2 = model.agent\n",
    "\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=200), \n",
    "                             num_games=100,\n",
    "                             temp = 0.25)\n",
    "\n",
    "results = eval_agents.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Agent:\n\tUnexpected key(s) in state_dict: \"online_net1.rank_plane\", \"online_net1.file_plane\", \"online_net2.rank_plane\", \"online_net2.file_plane\", \"target_net1.rank_plane\", \"target_net1.file_plane\", \"target_net2.rank_plane\", \"target_net2.file_plane\". \n\tsize mismatch for online_net1.stem.weight: copying a param with shape torch.Size([128, 14, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 18, 3, 3]).\n\tsize mismatch for online_net2.stem.weight: copying a param with shape torch.Size([128, 14, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 18, 3, 3]).\n\tsize mismatch for target_net1.stem.weight: copying a param with shape torch.Size([128, 14, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 18, 3, 3]).\n\tsize mismatch for target_net2.stem.weight: copying a param with shape torch.Size([128, 14, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 18, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = load_checkpoint(\u001b[33m\"\u001b[39m\u001b[33mmodel_conv_35000_episodes_large.pth\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m,  model)\n\u001b[32m      2\u001b[39m agent1 = deepcopy(model.agent)\n\u001b[32m      3\u001b[39m model = load_checkpoint(\u001b[33m\"\u001b[39m\u001b[33mmodel_conv_35000_episodes_large.pth\u001b[39m\u001b[33m\"\u001b[39m, model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:286\u001b[39m, in \u001b[36mload_checkpoint\u001b[39m\u001b[34m(core_path, memory_path, model)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_checkpoint\u001b[39m(core_path=\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[32m    283\u001b[39m                     memory_path=\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[32m    284\u001b[39m                     model=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    285\u001b[39m     checkpoint = torch.load(core_path, map_location=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m, weights_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     model.agent.load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    288\u001b[39m     model.opt_list[\u001b[32m0\u001b[39m].load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33moptimizer1_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    289\u001b[39m     model.opt_list[\u001b[32m1\u001b[39m].load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33moptimizer2_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for Agent:\n\tUnexpected key(s) in state_dict: \"online_net1.rank_plane\", \"online_net1.file_plane\", \"online_net2.rank_plane\", \"online_net2.file_plane\", \"target_net1.rank_plane\", \"target_net1.file_plane\", \"target_net2.rank_plane\", \"target_net2.file_plane\". \n\tsize mismatch for online_net1.stem.weight: copying a param with shape torch.Size([128, 14, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 18, 3, 3]).\n\tsize mismatch for online_net2.stem.weight: copying a param with shape torch.Size([128, 14, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 18, 3, 3]).\n\tsize mismatch for target_net1.stem.weight: copying a param with shape torch.Size([128, 14, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 18, 3, 3]).\n\tsize mismatch for target_net2.stem.weight: copying a param with shape torch.Size([128, 14, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 18, 3, 3])."
     ]
    }
   ],
   "source": [
    "model = load_checkpoint(\"model_conv_35000_episodes_large.pth\", None,  model)\n",
    "agent1 = deepcopy(model.agent)\n",
    "model = load_checkpoint(\"model_conv_35000_episodes_large.pth\", model)\n",
    "agent2 = model.agent\n",
    "\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=200,filter_blunder=True), \n",
    "                             num_games=100,\n",
    "                             temp = 0.25)\n",
    "\n",
    "results = eval_agents.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint(\"model_conv_35000_episodes_large.pth\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(max_num_moves=200,filter_blunder=False)\n",
    "environment.reset()\n",
    "#random.seed(42)\n",
    "#np.random.seed(42)\n",
    "#torch.manual_seed(42)\n",
    "temp = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = agent.select_action(environment, temp=temp, greedy=True)\n",
    "move = agent.action_to_move(action)\n",
    "\n",
    "board, (reward, done) = environment.step(move)\n",
    "\n",
    "state = agent.board_logic.board_to_state(board).to(config.device)\n",
    "\n",
    "Q1 = agent.online_net1(state).detach()\n",
    "Q2 = agent.online_net2(state).detach()\n",
    "legal_moves = environment.get_legal_moves()\n",
    "mask_legal = agent.get_mask_legal(legal_moves)\n",
    "\n",
    "Q1_legal = Q1[mask_legal]\n",
    "Q2_legal = Q2[mask_legal]\n",
    "\n",
    "diff = torch.abs(Q1_legal - Q2_legal)/torch.max(torch.abs(Q1_legal), torch.abs(Q2_legal))\n",
    "\n",
    "print(f\"{np.mean(diff.cpu().numpy()):.4f}\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -1e9)\n",
    "action_star = torch.argmax(Q_legal, dim=1).to(config.device)\n",
    "score = Q2[0,action_star[0]]\n",
    "\n",
    "if environment.mirror:\n",
    "    print(\"Black:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board.mirror())\n",
    "else:\n",
    "    print(\"White:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board)\n",
    "\n",
    "\n",
    "if board.is_checkmate():\n",
    "    print(\"checkmate!\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -float('inf'))\n",
    "#print(Q_legal[Q_legal>-1])\n",
    "\n",
    "q_max = Q_legal.max(dim=1, keepdim=True).values\n",
    "print(q_max)\n",
    "\n",
    "logits = (Q_legal - q_max)/temp\n",
    "print(torch.sort(logits, descending=True).values[0,:10])\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(probs[logits>-1])\n",
    "temp = temp*0.95\n",
    "print(f\"temp: {temp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.board_to_state(environment.get_board())[0,12]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
