{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu128\n",
      "CUDA toolkit version PyTorch was built with: 12.8\n",
      "cuDNN version: 90701\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import config\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import copy, deepcopy\n",
    "import cmath\n",
    "import chess\n",
    "from utils import saver, loader\n",
    "\n",
    "from agents import *\n",
    "from environments import *\n",
    "from models import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision = 3)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)  \n",
    "print(\"CUDA toolkit version PyTorch was built with:\", torch.version.cuda)  \n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version()) \n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456972\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "agent = Agent(board_logic = BoardLogic(), in_ch=14, ch=64, n_blocks=6)\n",
    "print(sum(p.numel() for p in agent.online_net1.parameters() if p.requires_grad))\n",
    "environment = Environment(max_num_moves=200,)\n",
    "\n",
    "opt_list = [None, None]\n",
    "\n",
    "model = Model(agent = agent,\n",
    "               environment = environment,\n",
    "               mem_capacity = 100000,\n",
    "               batch_size = 256,\n",
    "               num_warmup = 10000,\n",
    "               policy_update = 2,\n",
    "               tau = 0.01,\n",
    "               temp_scaler = TemperatureScaler(temp_start=0.6, \n",
    "                                               temp_end=0.3, \n",
    "                                               temp_min=1e-5, \n",
    "                                               episode_decay=5000, \n",
    "                                               transition_decay=0.95),\n",
    "               opt_list=opt_list,\n",
    "               scaler=torch.amp.GradScaler(\"cuda\")\n",
    "             )\n",
    "\n",
    "optimizer_grouped_parameters1 = group_decay_parameters(\n",
    "    agent.online_net1,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "optimizer_grouped_parameters2 = group_decay_parameters(\n",
    "    agent.online_net2,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "opt_list[0] = torch.optim.AdamW(optimizer_grouped_parameters1, lr=1e-4)\n",
    "opt_list[1] = torch.optim.AdamW(optimizer_grouped_parameters2, lr=1e-4)\n",
    "\n",
    "\n",
    "eval_agents = EvaluateAgents(agent1 = agent, \n",
    "                             agent2 = deepcopy(agent), \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=200,\n",
    "                             temp = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e9f3edf853403eb9683b6bb6df3da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c8e8e2e06a439e87e9c6338cc0f9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 41, -1: 18, 0: 41} tensor(0.0006, device='cuda:0') 1.0055442894185622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306f3934d0b84d6e951a32765df4b22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 36, -1: 22, 0: 42} tensor(0.0001, device='cuda:0') 0.9958092864821939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38fa8fee10841f08d51da2c2be6d94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 39, -1: 22, 0: 39} tensor(0.0003, device='cuda:0') 1.0777850253909242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d9b710a73547389560fe3fae23e297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 51, -1: 14, 0: 35} tensor(0.0001, device='cuda:0') 1.3529276678131685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342c121ef8534f7cb9e1acbccb1e0e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 62, -1: 13, 0: 25} tensor(0.0007, device='cuda:0') 0.860756922191849\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'memory_pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      3\u001b[39m eval_agents = EvaluateAgents(agent1 = agent1, \n\u001b[32m      4\u001b[39m                              agent2 = agent2, \n\u001b[32m      5\u001b[39m                              environment = Environment(max_num_moves=\u001b[32m200\u001b[39m,), \n\u001b[32m      6\u001b[39m                              num_games=\u001b[32m100\u001b[39m,\n\u001b[32m      7\u001b[39m                              temp = \u001b[32m0.25\u001b[39m)\n\u001b[32m      9\u001b[39m model.train(num_episodes = \u001b[32m5000\u001b[39m, \n\u001b[32m     10\u001b[39m             evaluate_agents = eval_agents,\n\u001b[32m     11\u001b[39m             freq=\u001b[32m1000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m save_checkpoint(model, filename=\u001b[33m\"\u001b[39m\u001b[33mmodel_conv_5000_episodes_small.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:252\u001b[39m, in \u001b[36msave_checkpoint\u001b[39m\u001b[34m(model, filename)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_checkpoint\u001b[39m(model, filename=\u001b[33m'\u001b[39m\u001b[33mcheckpoint.pth\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    248\u001b[39m     checkpoint = {\n\u001b[32m    249\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m: model.agent.state_dict(),\n\u001b[32m    250\u001b[39m         \u001b[33m'\u001b[39m\u001b[33moptimizer1_state_dict\u001b[39m\u001b[33m'\u001b[39m: model.opt_list[\u001b[32m0\u001b[39m].state_dict(),\n\u001b[32m    251\u001b[39m         \u001b[33m'\u001b[39m\u001b[33moptimizer2_state_dict\u001b[39m\u001b[33m'\u001b[39m: model.opt_list[\u001b[32m1\u001b[39m].state_dict(),\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmemory_pos\u001b[39m\u001b[33m'\u001b[39m: model.memory_pos,\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmemory_neg\u001b[39m\u001b[33m'\u001b[39m: model.memory_neg,\n\u001b[32m    254\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcounter_episode\u001b[39m\u001b[33m'\u001b[39m: model.counter_episode,\n\u001b[32m    255\u001b[39m     }\n\u001b[32m    256\u001b[39m     torch.save(checkpoint, filename)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Model' object has no attribute 'memory_pos'"
     ]
    }
   ],
   "source": [
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=100,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_checkpoint(model, filename=\"model_conv_5000_episodes_small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60a7a01057c4638b21a63887683ea9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=100,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_checkpoint(model, filename=\"model_conv_10000_episodes_small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(max_num_moves=200,)\n",
    "environment.reset()\n",
    "#random.seed(42)\n",
    "#np.random.seed(42)\n",
    "#torch.manual_seed(42)\n",
    "temp = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8416\n",
      "Black:\n",
      "score: 0.0404\n",
      "r . . . Q . . .\n",
      "p p . b . p p .\n",
      ". . . . . k . .\n",
      "q . . p . B p .\n",
      ". b . N n . . .\n",
      ". . . . P . . .\n",
      "P . P . K P . .\n",
      "R N . . . . . R\n",
      "tensor([[0.2265]], device='cuda:0')\n",
      "tensor([0.0521, 0.9479], device='cuda:0')\n",
      "temp: 0.0011\n"
     ]
    }
   ],
   "source": [
    "action = agent.select_action(environment, temp=temp, greedy=False)\n",
    "move = agent.action_to_move(action)\n",
    "\n",
    "board, (reward, done) = environment.step(move)\n",
    "\n",
    "state = agent.board_logic.board_to_state(board).to(config.device)\n",
    "\n",
    "Q1 = agent.online_net1(state).detach()\n",
    "Q2 = agent.online_net2(state).detach()\n",
    "legal_moves = environment.get_legal_moves()\n",
    "mask_legal = agent.get_mask_legal(legal_moves)\n",
    "\n",
    "Q1_legal = Q1[mask_legal]\n",
    "Q2_legal = Q2[mask_legal]\n",
    "\n",
    "diff = torch.abs(Q1_legal - Q2_legal)/torch.max(torch.abs(Q1_legal), torch.abs(Q2_legal))\n",
    "\n",
    "print(f\"{np.mean(diff.cpu().numpy()):.4f}\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -1e9)\n",
    "action_star = torch.argmax(Q_legal, dim=1).to(config.device)\n",
    "score = Q2[0,action_star[0]]\n",
    "\n",
    "if environment.mirror:\n",
    "    print(\"Black:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board.mirror())\n",
    "else:\n",
    "    print(\"White:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board)\n",
    "\n",
    "\n",
    "if board.is_checkmate():\n",
    "    print(\"checkmate!\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -float('inf'))\n",
    "#print(Q_legal[Q_legal>-1])\n",
    "\n",
    "q_max = Q_legal.max(dim=1, keepdim=True).values\n",
    "print(q_max)\n",
    "\n",
    "logits = (Q_legal - q_max)/temp\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(probs[probs>0.05])\n",
    "temp = temp*0.95\n",
    "print(f\"temp: {temp:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
