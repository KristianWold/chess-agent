{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu128\n",
      "CUDA toolkit version PyTorch was built with: 12.8\n",
      "cuDNN version: 90701\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import config\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import copy, deepcopy\n",
    "import cmath\n",
    "import chess\n",
    "from utils import saver, loader\n",
    "\n",
    "from agents import *\n",
    "from environments import *\n",
    "from models import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision = 3)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)  \n",
    "print(\"CUDA toolkit version PyTorch was built with:\", torch.version.cuda)  \n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version()) \n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2389452\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "agent = Agent(board_logic = BoardLogic(), in_ch=14, ch=128, n_blocks=8)\n",
    "print(sum(p.numel() for p in agent.online_net1.parameters() if p.requires_grad))\n",
    "\n",
    "opt_list = [None, None]\n",
    "\n",
    "model = Model(agent = agent,\n",
    "               environment = Environment(max_num_moves=200,),\n",
    "               mem_capacity = 250000,\n",
    "               batch_size = 512,\n",
    "               num_warmup = 25000,\n",
    "               policy_update = 2,\n",
    "               target_update = 5000,\n",
    "               temp_constants = (0.6, 0.3, 1e-3, 10000),\n",
    "               opt_list=opt_list,\n",
    "               scaler=torch.amp.GradScaler(\"cuda\")\n",
    "             )\n",
    "\n",
    "optimizer_grouped_parameters1 = group_decay_parameters(\n",
    "    agent.online_net1,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "optimizer_grouped_parameters2 = group_decay_parameters(\n",
    "    agent.online_net2,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "opt_list[0] = torch.optim.AdamW(optimizer_grouped_parameters1, lr=1e-4)\n",
    "opt_list[1] = torch.optim.AdamW(optimizer_grouped_parameters2, lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac92c79105a4988bd361d117628c681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristian/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1263: UserWarning: Dynamo does not know how to trace the builtin `<unknown module>.Random.random.` This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind).\n",
      "If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround.\n",
      "If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use `torch.compiler.allow_in_graph`.\n",
      "  torch._dynamo.utils.warn_once(explanation + \"\\n\" + \"\\n\".join(hints))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90aa966773ef4c6a8bffec908376b622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 196, -1: 165, 0: 139} tensor(0.0052, device='cuda:0') 0.5038553457431083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dd8eafd95845378aee9aeebbb6a6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 177, -1: 184, 0: 139} tensor(0.0052, device='cuda:0') 0.4751294122907916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da11ccaa3830456d9febacb117b15547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 192, -1: 180, 0: 128} tensor(0.0032, device='cuda:0') 0.5079688577293404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330852fc833a466083cebbda7ff7dbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 169, -1: 188, 0: 143} tensor(0.0073, device='cuda:0') 0.37787426075263414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c1c68f62c74653931779d37d3cdda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 171, -1: 182, 0: 147} tensor(0.0066, device='cuda:0') 0.5027590940070181\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      4\u001b[39m agent2 = deepcopy(agent1)\n\u001b[32m      5\u001b[39m eval_agents = EvaluateAgents(agent1 = agent1, \n\u001b[32m      6\u001b[39m                              agent2 = agent2, \n\u001b[32m      7\u001b[39m                              environment = Environment(max_num_moves=\u001b[32m200\u001b[39m,), \n\u001b[32m      8\u001b[39m                              num_games=\u001b[32m500\u001b[39m,\n\u001b[32m      9\u001b[39m                              temp = \u001b[32m0.25\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m model.train(num_episodes = \u001b[32m5000\u001b[39m, \n\u001b[32m     12\u001b[39m             evaluate_agents = eval_agents,\n\u001b[32m     13\u001b[39m             freq=\u001b[32m1000\u001b[39m)\n\u001b[32m     15\u001b[39m save_checkpoint(model, filename=\u001b[33m\"\u001b[39m\u001b[33mmodel_conv_30000_episodes_large.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:140\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, num_episodes, evaluate_agents, freq)\u001b[39m\n\u001b[32m    137\u001b[39m state = state_next\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m counter % \u001b[38;5;28mself\u001b[39m.policy_update == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m.optimize_agent()\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m counter % \u001b[38;5;28mself\u001b[39m.target_update == \u001b[32m0\u001b[39m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m.agent.update_target_net()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:234\u001b[39m, in \u001b[36mModel.optimize_agent\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    231\u001b[39m torch.nn.utils.clip_grad_norm_(params, max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m    233\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.step(opt)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n\u001b[32m    235\u001b[39m opt.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/amp/grad_scaler.py:513\u001b[39m, in \u001b[36mGradScaler.update\u001b[39m\u001b[34m(self, new_scale)\u001b[39m\n\u001b[32m    508\u001b[39m         \u001b[38;5;28mself\u001b[39m._scale.copy_(new_scale)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    510\u001b[39m     \u001b[38;5;66;03m# Consume shared inf/nan data collected from optimizers to update the scale.\u001b[39;00m\n\u001b[32m    511\u001b[39m     \u001b[38;5;66;03m# If all found_inf tensors are on the same device as self._scale, this operation is asynchronous.\u001b[39;00m\n\u001b[32m    512\u001b[39m     found_infs = [\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m         found_inf.to(device=_scale.device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    514\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._per_optimizer_states.values()\n\u001b[32m    515\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m found_inf \u001b[38;5;129;01min\u001b[39;00m state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()\n\u001b[32m    516\u001b[39m     ]\n\u001b[32m    518\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(found_infs) > \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded prior to update.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    520\u001b[39m     found_inf_combined = found_infs[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = load_checkpoint(\"model_conv_25000_episodes_large.pth\", model)\n",
    "\n",
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=500,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_checkpoint(model, filename=\"model_conv_30000_episodes_large.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model, filename=\"model_conv_30000_episodes_large.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(max_num_moves=200,)\n",
    "environment.reset()\n",
    "#random.seed(42)\n",
    "#np.random.seed(42)\n",
    "#torch.manual_seed(42)\n",
    "temp = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0256\n",
      "Black:\n",
      "score: -0.1093\n",
      "r n b q k b n .\n",
      ". p p . p p p .\n",
      "p . . . . . . r\n",
      ". . . p . . . P\n",
      ". . . . . . . .\n",
      ". . P P . P . .\n",
      "P P . . P . . P\n",
      "R N B Q K B N R\n",
      "tensor([[-0.1268]], device='cuda:0')\n",
      "tensor([-0.1537,  0.0000, -0.5983, -0.6836, -0.1277], device='cuda:0')\n",
      "tensor([0.1212, 0.1413, 0.0777, 0.0713, 0.1244], device='cuda:0')\n",
      "temp: 0.0630\n"
     ]
    }
   ],
   "source": [
    "action = agent.select_action(environment, temp=temp, greedy=False)\n",
    "move = agent.action_to_move(action)\n",
    "\n",
    "board, (reward, done) = environment.step(move)\n",
    "\n",
    "state = agent.board_logic.board_to_state(board).to(config.device)\n",
    "\n",
    "Q1 = agent.online_net1(state).detach()\n",
    "Q2 = agent.online_net2(state).detach()\n",
    "legal_moves = environment.get_legal_moves()\n",
    "mask_legal = agent.get_mask_legal(legal_moves)\n",
    "\n",
    "Q1_legal = Q1[mask_legal]\n",
    "Q2_legal = Q2[mask_legal]\n",
    "\n",
    "diff = torch.abs(Q1_legal - Q2_legal)/torch.max(torch.abs(Q1_legal), torch.abs(Q2_legal))\n",
    "\n",
    "print(f\"{np.mean(diff.cpu().numpy()):.4f}\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -1e9)\n",
    "action_star = torch.argmax(Q_legal, dim=1).to(config.device)\n",
    "score = Q2[0,action_star[0]]\n",
    "\n",
    "if environment.mirror:\n",
    "    print(\"Black:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board.mirror())\n",
    "else:\n",
    "    print(\"White:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board)\n",
    "\n",
    "\n",
    "if board.is_checkmate():\n",
    "    print(\"checkmate!\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -float('inf'))\n",
    "#print(Q_legal[Q_legal>-1])\n",
    "\n",
    "q_max = Q_legal.max(dim=1, keepdim=True).values\n",
    "#print(q_max)\n",
    "\n",
    "logits = (Q_legal - q_max)/temp\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(logits[logits>-1])\n",
    "print(probs[probs>0.05])\n",
    "temp = temp*0.95\n",
    "print(f\"temp: {temp:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
