{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu128\n",
      "CUDA toolkit version PyTorch was built with: 12.8\n",
      "cuDNN version: 90701\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import config\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import copy, deepcopy\n",
    "import cmath\n",
    "import chess\n",
    "from utils import saver, loader\n",
    "\n",
    "from agents import *\n",
    "from environments import *\n",
    "from models import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision = 3)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)  \n",
    "print(\"CUDA toolkit version PyTorch was built with:\", torch.version.cuda)  \n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version()) \n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456972\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "agent = Agent(board_logic = BoardLogic(), in_ch=14, ch=64, n_blocks=6)\n",
    "print(sum(p.numel() for p in agent.online_net1.parameters() if p.requires_grad))\n",
    "\n",
    "opt_list = [None, None]\n",
    "\n",
    "model = Model(agent = agent,\n",
    "               environment = Environment(max_num_moves=200,),\n",
    "               mem_capacity = 200000,\n",
    "               batch_size = 128,\n",
    "               num_warmup = 20000,\n",
    "               policy_update = 2,\n",
    "               target_update = 5000,\n",
    "               temp_constants = (0.6, 0.3, 1e-3, 5000),\n",
    "               opt_list=opt_list,\n",
    "               scaler=torch.amp.GradScaler(\"cuda\")\n",
    "             )\n",
    "\n",
    "optimizer_grouped_parameters1 = group_decay_parameters(\n",
    "    agent.online_net1,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "optimizer_grouped_parameters2 = group_decay_parameters(\n",
    "    agent.online_net2,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "opt_list[0] = torch.optim.AdamW(optimizer_grouped_parameters1, lr=1e-4)\n",
    "opt_list[1] = torch.optim.AdamW(optimizer_grouped_parameters2, lr=1e-4)\n",
    "\n",
    "\n",
    "eval_agents = EvaluateAgents(agent1 = agent, \n",
    "                             agent2 = deepcopy(agent), \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=200,\n",
    "                             temp = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4897d0b5333546ffa9d62317a0317c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristian/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1263: UserWarning: Dynamo does not know how to trace the builtin `<unknown module>.Random.random.` This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind).\n",
      "If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround.\n",
      "If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use `torch.compiler.allow_in_graph`.\n",
      "  torch._dynamo.utils.warn_once(explanation + \"\\n\" + \"\\n\".join(hints))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c854d401ff14f6e871f7976519e7da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 63, -1: 72, 0: 65} tensor(0.0065, device='cuda:0') 0.7883519714369494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafb017513974e5b95d931d42189a550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 78, -1: 66, 0: 56} tensor(0.0029, device='cuda:0') 0.6960866397804045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a7d6393e504e5082ef69566279548c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 79, -1: 69, 0: 52} tensor(0.0055, device='cuda:0') 0.2999238836043698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b826e341e97f43a1ac48ef103bc5d922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 78, -1: 59, 0: 63} tensor(0.0040, device='cuda:0') 0.3548629458831704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72271849bfa4cbd99193d5612ce92e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 69, -1: 58, 0: 73} tensor(0.0080, device='cuda:0') 0.27287885174155235\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint(filename=\"model_conv_25000_episodes_small.pth\", model=model)\n",
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=200,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_checkpoint(model, filename=\"model_conv_30000_episodes_small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8c896af4bf43bba7ddfc001ba39f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b09296a480a40918bfb0126534cd630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 133, -1: 132, 0: 135} tensor(0.0021, device='cuda:0') 0.3009740471634574\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m agent2 = deepcopy(agent1)\n\u001b[32m      4\u001b[39m eval_agents = EvaluateAgents(agent1 = agent1, \n\u001b[32m      5\u001b[39m                              agent2 = agent2, \n\u001b[32m      6\u001b[39m                              environment = Environment(max_num_moves=\u001b[32m200\u001b[39m,), \n\u001b[32m      7\u001b[39m                              num_games=\u001b[32m400\u001b[39m,\n\u001b[32m      8\u001b[39m                              temp = \u001b[32m0.25\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model.train(num_episodes = \u001b[32m10000\u001b[39m, \n\u001b[32m     11\u001b[39m             evaluate_agents = eval_agents,\n\u001b[32m     12\u001b[39m             freq=\u001b[32m2000\u001b[39m)\n\u001b[32m     14\u001b[39m save_checkpoint(model, filename=\u001b[33m\"\u001b[39m\u001b[33mmodel_conv_40000_episodes_small.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:114\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, num_episodes, evaluate_agents, freq)\u001b[39m\n\u001b[32m    111\u001b[39m done = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     action = \u001b[38;5;28mself\u001b[39m.agent.select_action(\u001b[38;5;28mself\u001b[39m.environment, \n\u001b[32m    115\u001b[39m                                       temp=temp, \n\u001b[32m    116\u001b[39m                                       greedy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    117\u001b[39m     temp *= \u001b[32m0.95\u001b[39m \n\u001b[32m    119\u001b[39m     move = \u001b[38;5;28mself\u001b[39m.agent.action_to_move(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/agents.py:123\u001b[39m, in \u001b[36mAgent.select_action\u001b[39m\u001b[34m(self, environment, temp, greedy)\u001b[39m\n\u001b[32m    120\u001b[39m state_tensor = \u001b[38;5;28mself\u001b[39m.board_logic.board_to_state(board).to(config.device)\n\u001b[32m    121\u001b[39m mask_legal = \u001b[38;5;28mself\u001b[39m.get_mask_legal(legal_moves)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m Q = \u001b[38;5;28mself\u001b[39m.forward(state_tensor)\n\u001b[32m    125\u001b[39m Q_legal = Q.masked_fill(~mask_legal, -\u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    126\u001b[39m max_q = Q_legal.max(dim=\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m).values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/agents.py:105\u001b[39m, in \u001b[36mAgent.forward\u001b[39m\u001b[34m(self, state_tensor, network_id)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_tensor, network_id=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    104\u001b[39m     Q1 = \u001b[38;5;28mself\u001b[39m.online_net1(state_tensor)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     Q2 = \u001b[38;5;28mself\u001b[39m.online_net2(state_tensor)\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (Q1 + Q2) / \u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/agents.py:72\u001b[39m, in \u001b[36mConvNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     69\u001b[39m x = x.float()\n\u001b[32m     71\u001b[39m r_plane = \u001b[38;5;28mself\u001b[39m.rank_plane.repeat(x.size(\u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m).to(x.device)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m f_plane = \u001b[38;5;28mself\u001b[39m.file_plane.repeat(x.size(\u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m).to(x.device)\n\u001b[32m     73\u001b[39m x = torch.cat([x, r_plane, f_plane], dim=\u001b[32m1\u001b[39m)\n\u001b[32m     75\u001b[39m x = F.silu(\u001b[38;5;28mself\u001b[39m.stem(x))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = load_checkpoint(filename=\"model_conv_30000_episodes_small.pth\", model=model)\n",
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=400,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 10000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=2000)\n",
    "\n",
    "save_checkpoint(model, filename=\"model_conv_40000_episodes_small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint(filename=\"model_conv_30000_episodes_small.pth\", model=model)\n",
    "agent1 = model.agent\n",
    "model = load_checkpoint(filename=\"model_conv_15000_episodes_small.pth\", model=model)\n",
    "agent2 = model.agent\n",
    "\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=1000,\n",
    "                             temp = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e12e64a71c242ccb686d359c903da71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 346, -1: 356, 0: 298}\n"
     ]
    }
   ],
   "source": [
    "results = eval_agents.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(max_num_moves=200,)\n",
    "environment.reset()\n",
    "#random.seed(42)\n",
    "#np.random.seed(42)\n",
    "#torch.manual_seed(42)\n",
    "temp = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7064\n",
      "Black:\n",
      "score: -0.0086\n",
      "r . . . k b . r\n",
      "p . n . p . . .\n",
      "B . . . P . . n\n",
      "q . p p . . . p\n",
      ". . P . . p P R\n",
      ". b . P . N . .\n",
      "P B . . . P K .\n",
      "R N . . . Q . .\n",
      "tensor([[0.0350]], device='cuda:0')\n",
      "tensor([0.0693, 0.0102, 0.3230, 0.4156, 0.0194, 0.1232], device='cuda:0')\n",
      "temp: 0.0183\n"
     ]
    }
   ],
   "source": [
    "action = agent.select_action(environment, temp=0.25, greedy=False)\n",
    "move = agent.action_to_move(action)\n",
    "\n",
    "board, (reward, done) = environment.step(move)\n",
    "\n",
    "state = agent.board_logic.board_to_state(board).to(config.device)\n",
    "\n",
    "Q1 = agent.online_net1(state).detach()\n",
    "Q2 = agent.online_net2(state).detach()\n",
    "legal_moves = environment.get_legal_moves()\n",
    "mask_legal = agent.get_mask_legal(legal_moves)\n",
    "\n",
    "Q1_legal = Q1[mask_legal]\n",
    "Q2_legal = Q2[mask_legal]\n",
    "\n",
    "diff = torch.abs(Q1_legal - Q2_legal)/torch.max(torch.abs(Q1_legal), torch.abs(Q2_legal))\n",
    "\n",
    "print(f\"{np.mean(diff.cpu().numpy()):.4f}\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -1e9)\n",
    "action_star = torch.argmax(Q_legal, dim=1).to(config.device)\n",
    "score = Q2[0,action_star[0]]\n",
    "\n",
    "if environment.mirror:\n",
    "    print(\"Black:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board.mirror())\n",
    "else:\n",
    "    print(\"White:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board)\n",
    "\n",
    "\n",
    "if board.is_checkmate():\n",
    "    print(\"checkmate!\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -float('inf'))\n",
    "#print(Q_legal[Q_legal>-1])\n",
    "\n",
    "q_max = Q_legal.max(dim=1, keepdim=True).values\n",
    "print(q_max)\n",
    "\n",
    "logits = (Q_legal - q_max)/temp\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(probs[probs>0.01])\n",
    "temp = temp*0.95\n",
    "print(f\"temp: {temp:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
