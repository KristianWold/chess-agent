{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu128\n",
      "CUDA toolkit version PyTorch was built with: 12.8\n",
      "cuDNN version: 90701\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import config\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import copy, deepcopy\n",
    "import cmath\n",
    "import chess\n",
    "from utils import saver, loader\n",
    "\n",
    "from agents import *\n",
    "from environments import *\n",
    "from models import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision = 3)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)  \n",
    "print(\"CUDA toolkit version PyTorch was built with:\", torch.version.cuda)  \n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version()) \n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456972\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "agent = Agent(board_logic = BoardLogic(), in_ch=14, ch=64, n_blocks=6)\n",
    "print(sum(p.numel() for p in agent.online_net1.parameters() if p.requires_grad))\n",
    "\n",
    "opt_list = [None, None]\n",
    "\n",
    "model = Model(agent = agent,\n",
    "               environment = Environment(max_num_moves=200,),\n",
    "               mem_capacity = 200000,\n",
    "               batch_size = 128,\n",
    "               num_warmup = 20000,\n",
    "               policy_update = 2,\n",
    "               target_update = 5000,\n",
    "               temp_constants = (0.6, 0.3, 1e-3, 5000),\n",
    "               opt_list=opt_list,\n",
    "               scaler=torch.amp.GradScaler(\"cuda\")\n",
    "             )\n",
    "\n",
    "optimizer_grouped_parameters1 = group_decay_parameters(\n",
    "    agent.online_net1,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "optimizer_grouped_parameters2 = group_decay_parameters(\n",
    "    agent.online_net2,\n",
    "    weight_decay=1e-5,\n",
    "    no_decay=[\"bias\", \"GroupNorm.weight\"],\n",
    "    )\n",
    "\n",
    "opt_list[0] = torch.optim.AdamW(optimizer_grouped_parameters1, lr=1e-4)\n",
    "opt_list[1] = torch.optim.AdamW(optimizer_grouped_parameters2, lr=1e-4)\n",
    "\n",
    "\n",
    "eval_agents = EvaluateAgents(agent1 = agent, \n",
    "                             agent2 = deepcopy(agent), \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=200,\n",
    "                             temp = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d8adaa2f704b7683422880018de1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristian/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1263: UserWarning: Dynamo does not know how to trace the builtin `<unknown module>.Random.random.` This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind).\n",
      "If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround.\n",
      "If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use `torch.compiler.allow_in_graph`.\n",
      "  torch._dynamo.utils.warn_once(explanation + \"\\n\" + \"\\n\".join(hints))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff90fcb9d9c4b328a409d2660c4cfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 63, -1: 72, 0: 65} tensor(0.0065, device='cuda:0') 0.7883519714369494\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m agent2 = deepcopy(agent1)\n\u001b[32m      4\u001b[39m eval_agents = EvaluateAgents(agent1 = agent1, \n\u001b[32m      5\u001b[39m                              agent2 = agent2, \n\u001b[32m      6\u001b[39m                              environment = Environment(max_num_moves=\u001b[32m200\u001b[39m,), \n\u001b[32m      7\u001b[39m                              num_games=\u001b[32m200\u001b[39m,\n\u001b[32m      8\u001b[39m                              temp = \u001b[32m0.25\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model.train(num_episodes = \u001b[32m5000\u001b[39m, \n\u001b[32m     11\u001b[39m             evaluate_agents = eval_agents,\n\u001b[32m     12\u001b[39m             freq=\u001b[32m1000\u001b[39m)\n\u001b[32m     14\u001b[39m save_checkpoint(model, filename=\u001b[33m\"\u001b[39m\u001b[33mmodel_conv_30000_episodes_small.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:140\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, num_episodes, evaluate_agents, freq)\u001b[39m\n\u001b[32m    137\u001b[39m state = state_next\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m counter % \u001b[38;5;28mself\u001b[39m.policy_update == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m.optimize_agent()\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m counter % \u001b[38;5;28mself\u001b[39m.target_update == \u001b[32m0\u001b[39m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m.agent.update_target_net()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:222\u001b[39m, in \u001b[36mModel.optimize_agent\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize_agent\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autocast(device_type=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype=torch.float16):\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m         loss, opt = \u001b[38;5;28mself\u001b[39m.compute_loss()\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m loss == \u001b[32m0\u001b[39m:\n\u001b[32m    224\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:655\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    652\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:175\u001b[39m, in \u001b[36mModel.compute_loss\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.memory_pos.num_samples < \u001b[38;5;28mself\u001b[39m.num_warmup \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.memory_neg.num_samples < \u001b[38;5;28mself\u001b[39m.num_warmup:\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m state_batch, action_batch, next_state_batch, mask_legal_batch, reward_batch, done_batch = \u001b[38;5;28mself\u001b[39m.sample_memory()\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m random.random() < \u001b[32m0.5\u001b[39m:\n\u001b[32m    178\u001b[39m     online_net = \u001b[38;5;28mself\u001b[39m.agent.online_net1\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:207\u001b[39m, in \u001b[36mModel.sample_memory\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.memory_pos.num_samples < \u001b[38;5;28mself\u001b[39m.num_warmup \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.memory_neg.num_samples < \u001b[38;5;28mself\u001b[39m.num_warmup:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m state_batch1, action_batch1, next_state_batch1, mask_legal_batch1, reward_batch1, done_batch1 = \u001b[38;5;28mself\u001b[39m.memory_pos.sample()\n\u001b[32m    208\u001b[39m state_batch2, action_batch2, next_state_batch2, mask_legal_batch2, reward_batch2, done_batch2 = \u001b[38;5;28mself\u001b[39m.memory_neg.sample()\n\u001b[32m    210\u001b[39m state_batch = torch.cat([state_batch1, state_batch2], dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:208\u001b[39m, in \u001b[36mtorch_dynamo_resume_in_sample_memory_at_207\u001b[39m\u001b[34m(___stack0, self)\u001b[39m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    207\u001b[39m state_batch1, action_batch1, next_state_batch1, mask_legal_batch1, reward_batch1, done_batch1 = \u001b[38;5;28mself\u001b[39m.memory_pos.sample()\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m state_batch2, action_batch2, next_state_batch2, mask_legal_batch2, reward_batch2, done_batch2 = \u001b[38;5;28mself\u001b[39m.memory_neg.sample()\n\u001b[32m    210\u001b[39m state_batch = torch.cat([state_batch1, state_batch2], dim=\u001b[32m0\u001b[39m)\n\u001b[32m    211\u001b[39m action_batch = torch.cat([action_batch1, action_batch2], dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:47\u001b[39m, in \u001b[36mReplayMemory.sample\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m.index = (\u001b[38;5;28mself\u001b[39m.index + \u001b[32m1\u001b[39m) % \u001b[38;5;28mself\u001b[39m.capacity\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m.num_samples = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_samples + \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.capacity)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msample\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     48\u001b[39m     idx = torch.randperm(\u001b[38;5;28mself\u001b[39m.num_samples)[:\u001b[38;5;28mself\u001b[39m.batch_size]\n\u001b[32m     49\u001b[39m     batch = [b.to(config.device) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data[idx]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1209\u001b[39m, in \u001b[36maot_module_simplified.<locals>.forward\u001b[39m\u001b[34m(*runtime_args)\u001b[39m\n\u001b[32m   1207\u001b[39m full_args.extend(params_flat)\n\u001b[32m   1208\u001b[39m full_args.extend(runtime_args)\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn(full_args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:328\u001b[39m, in \u001b[36m_create_runtime_wrapper.<locals>.runtime_wrapper\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n\u001b[32m    327\u001b[39m         torch._C._set_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     all_outs = call_func_at_runtime_with_args(\n\u001b[32m    329\u001b[39m         compiled_fn, args, disable_amp=disable_amp, steal_args=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    330\u001b[39m     )\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:126\u001b[39m, in \u001b[36mcall_func_at_runtime_with_args\u001b[39m\u001b[34m(f, args, steal_args, disable_amp)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[33m\"\u001b[39m\u001b[33m_boxed_call\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         out = normalize_as_list(f(args))\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    128\u001b[39m         \u001b[38;5;66;03m# TODO: Please remove soon\u001b[39;00m\n\u001b[32m    129\u001b[39m         \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[32m    130\u001b[39m         warnings.warn(\n\u001b[32m    131\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYour compiler for AOTAutograd is returning a function that doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt take boxed arguments. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    132\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:495\u001b[39m, in \u001b[36mFunctionalizedRngRuntimeWrapper.post_compile.<locals>.wrapper\u001b[39m\u001b[34m(runtime_args)\u001b[39m\n\u001b[32m    488\u001b[39m     out = \u001b[38;5;28mself\u001b[39m._functionalized_rng_runtime_epilogue(\n\u001b[32m    489\u001b[39m         runtime_metadata,\n\u001b[32m    490\u001b[39m         out,\n\u001b[32m    491\u001b[39m         \u001b[38;5;66;03m# TODO: this won't be right for the backward when we convert the call_compiled_backward to use the wrapper\u001b[39;00m\n\u001b[32m    492\u001b[39m         runtime_metadata.num_forward_returns,\n\u001b[32m    493\u001b[39m     )\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn(runtime_args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_inductor/output_code.py:460\u001b[39m, in \u001b[36mCompiledFxGraph.__call__\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_callable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_callable(inputs)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    462\u001b[39m     get_runtime_metrics_context().finish()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/torchinductor_kristian/47/c47jh2iycbaqdbqfsejjrd2he63kldl3mpuxgbofu2xwwumpigal.py:36\u001b[39m, in \u001b[36mcall\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(args):\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Topologically Sorted Source Nodes: [randperm], Original ATen: [aten.randperm]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     buf0 = torch.ops.aten.randperm.default(\u001b[32m200000\u001b[39m, device=device(\u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m), pin_memory=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     37\u001b[39m     buf1 = buf0\n\u001b[32m     38\u001b[39m     assert_size_stride(buf1, (\u001b[32m200000\u001b[39m, ), (\u001b[32m1\u001b[39m, ))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_ops.py:756\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._op(*args, **kwargs)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = load_checkpoint(filename=\"model_conv_25000_episodes_small.pth\", model=model)\n",
    "agent1 = model.agent\n",
    "agent2 = deepcopy(agent1)\n",
    "eval_agents = EvaluateAgents(agent1 = agent1, \n",
    "                             agent2 = agent2, \n",
    "                             environment = Environment(max_num_moves=200,), \n",
    "                             num_games=200,\n",
    "                             temp = 0.25)\n",
    "\n",
    "model.train(num_episodes = 5000, \n",
    "            evaluate_agents = eval_agents,\n",
    "            freq=1000)\n",
    "\n",
    "save_checkpoint(model, filename=\"model_conv_30000_episodes_small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint(filename=\"model_conv_25000_episodes_small.pth\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(max_num_moves=200,)\n",
    "environment.reset()\n",
    "#random.seed(42)\n",
    "#np.random.seed(42)\n",
    "#torch.manual_seed(42)\n",
    "temp = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7064\n",
      "Black:\n",
      "score: -0.0086\n",
      "r . . . k b . r\n",
      "p . n . p . . .\n",
      "B . . . P . . n\n",
      "q . p p . . . p\n",
      ". . P . . p P R\n",
      ". b . P . N . .\n",
      "P B . . . P K .\n",
      "R N . . . Q . .\n",
      "tensor([[0.0350]], device='cuda:0')\n",
      "tensor([0.0693, 0.0102, 0.3230, 0.4156, 0.0194, 0.1232], device='cuda:0')\n",
      "temp: 0.0183\n"
     ]
    }
   ],
   "source": [
    "action = agent.select_action(environment, temp=0.25, greedy=False)\n",
    "move = agent.action_to_move(action)\n",
    "\n",
    "board, (reward, done) = environment.step(move)\n",
    "\n",
    "state = agent.board_logic.board_to_state(board).to(config.device)\n",
    "\n",
    "Q1 = agent.online_net1(state).detach()\n",
    "Q2 = agent.online_net2(state).detach()\n",
    "legal_moves = environment.get_legal_moves()\n",
    "mask_legal = agent.get_mask_legal(legal_moves)\n",
    "\n",
    "Q1_legal = Q1[mask_legal]\n",
    "Q2_legal = Q2[mask_legal]\n",
    "\n",
    "diff = torch.abs(Q1_legal - Q2_legal)/torch.max(torch.abs(Q1_legal), torch.abs(Q2_legal))\n",
    "\n",
    "print(f\"{np.mean(diff.cpu().numpy()):.4f}\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -1e9)\n",
    "action_star = torch.argmax(Q_legal, dim=1).to(config.device)\n",
    "score = Q2[0,action_star[0]]\n",
    "\n",
    "if environment.mirror:\n",
    "    print(\"Black:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board.mirror())\n",
    "else:\n",
    "    print(\"White:\")\n",
    "    print(f\"score: {score.item():.4f}\")\n",
    "    print(board)\n",
    "\n",
    "\n",
    "if board.is_checkmate():\n",
    "    print(\"checkmate!\")\n",
    "\n",
    "Q_legal = Q1.masked_fill(~mask_legal, -float('inf'))\n",
    "#print(Q_legal[Q_legal>-1])\n",
    "\n",
    "q_max = Q_legal.max(dim=1, keepdim=True).values\n",
    "print(q_max)\n",
    "\n",
    "logits = (Q_legal - q_max)/temp\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(probs[probs>0.01])\n",
    "temp = temp*0.95\n",
    "print(f\"temp: {temp:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
