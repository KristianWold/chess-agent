{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu128\n",
      "CUDA toolkit version PyTorch was built with: 12.8\n",
      "cuDNN version: 90701\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import config\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import copy, deepcopy\n",
    "import cmath\n",
    "import chess\n",
    "\n",
    "from basis_gates import *\n",
    "from agents import *\n",
    "from environments import *\n",
    "from models import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision = 3)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)  \n",
    "print(\"CUDA toolkit version PyTorch was built with:\", torch.version.cuda)  \n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version()) \n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "logger = Logger(sample_freq = 1000)\n",
    "\n",
    "agent = Agent(board_logic = BoardLogic())\n",
    "\n",
    "\n",
    "opt_list = [torch.optim.Adam(agent.online_net1.parameters(), lr=1e-6), \n",
    "            torch.optim.Adam(agent.online_net2.parameters(), lr=1e-6)]\n",
    "\n",
    "model = Model(agent = agent,\n",
    "               environment = Environment(max_num_moves=200,),\n",
    "               mem_capacity = 100000,\n",
    "               batch_size = 128,\n",
    "               batch_size_min = 128,\n",
    "               policy_update = 1,\n",
    "               target_update = 25000,\n",
    "               temp_constants = (2, 1, 1e-5, 100000),\n",
    "               opt_list=opt_list,\n",
    "               scaler=torch.amp.GradScaler(\"cuda\")\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.Board()\n",
    "board1 = deepcopy(board)\n",
    "board.push(board.legal_moves.__iter__().__next__())\n",
    "board2 = deepcopy(board)\n",
    "board.push(board.legal_moves.__iter__().__next__())\n",
    "board3 = deepcopy(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_list = [board1, board2, board3]\n",
    "\n",
    "states = agent.board_logic.board_to_state(board_list)\n",
    "Q = agent.forward(states)\n",
    "mask = agent.get_mask_legal(board_list)\n",
    "\n",
    "Q_masked = Q.masked_fill(~mask, -1e9)\n",
    "action = Q_masked.argmax(dim=1)\n",
    "moves = agent.action_to_move(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 8, 8])\n",
      "torch.Size([2, 4864])\n",
      "tensor([[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    board = chess.Board()\n",
    "    board2 = chess.Board()\n",
    "    board2.push(chess.Move.from_uci(\"e2e4\"))\n",
    "    board2.push(chess.Move.from_uci(\"e7e5\"))\n",
    "\n",
    "    board_logic = BoardLogic()\n",
    "    state_dim = 64*76\n",
    "\n",
    "    state1 = agent.board_logic.board_to_state([board]).to(config.device)\n",
    "    state2 = agent.board_logic.board_to_state([board2]).to(config.device)\n",
    "\n",
    "    state = torch.concat([state1, state2], dim=0)\n",
    "    print(state.shape)\n",
    "    Q = agent.forward(state)\n",
    "    print(Q.shape)\n",
    "\n",
    "    moves1 = torch.tensor([board_logic.move_to_action(m) for m in board.legal_moves], dtype=torch.long).to(config.device)\n",
    "    moves2 = torch.tensor([board_logic.move_to_action(m) for m in board2.legal_moves], dtype=torch.long).to(config.device)\n",
    "\n",
    "    mask = torch.zeros((2,state_dim), dtype=torch.bool).to(config.device)\n",
    "    mask[0, moves1] = True\n",
    "    mask[1, moves2] = True\n",
    "\n",
    "    Q[~mask] = -1e9\n",
    "\n",
    "    print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c00fe9ae1d4bd38aa1bf4e6f806900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 20:50:32.369000 525614 site-packages/torch/_dynamo/convert_frame.py:964] [1/8] torch._dynamo hit config.recompile_limit (8)\n",
      "W0916 20:50:32.369000 525614 site-packages/torch/_dynamo/convert_frame.py:964] [1/8]    function: 'sample' (/home/kristian/Documents/chess-agent/notebooks/Experiments/../../src/models.py:64)\n",
      "W0916 20:50:32.369000 525614 site-packages/torch/_dynamo/convert_frame.py:964] [1/8]    last reason: 1/7: len(self.buffer) == 135                                \n",
      "W0916 20:50:32.369000 525614 site-packages/torch/_dynamo/convert_frame.py:964] [1/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W0916 20:50:32.369000 525614 site-packages/torch/_dynamo/convert_frame.py:964] [1/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.Size([128, 1]) torch.Size([128, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model.train(num_episodes = \u001b[32m1000\u001b[39m, logger = logger)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:167\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, num_episodes, logger)\u001b[39m\n\u001b[32m    164\u001b[39m state = state_next\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m counter % \u001b[38;5;28mself\u001b[39m.policy_update == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m.optimize_agent()\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m counter % \u001b[38;5;28mself\u001b[39m.target_update == \u001b[32m0\u001b[39m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28mself\u001b[39m.agent.update_target_net()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/chess-agent/notebooks/Experiments/../../src/models.py:228\u001b[39m, in \u001b[36mModel.optimize_agent\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Optimize the model\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.scale(loss).backward()\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.step(opt)\n\u001b[32m    229\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n\u001b[32m    230\u001b[39m opt.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/amp/grad_scaler.py:461\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    458\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    459\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m retval = \u001b[38;5;28mself\u001b[39m._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n\u001b[32m    463\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/amp/grad_scaler.py:356\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    354\u001b[39m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = func(*args, **kwargs)\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     adam(\n\u001b[32m    247\u001b[39m         params_with_grad,\n\u001b[32m    248\u001b[39m         grads,\n\u001b[32m    249\u001b[39m         exp_avgs,\n\u001b[32m    250\u001b[39m         exp_avg_sqs,\n\u001b[32m    251\u001b[39m         max_exp_avg_sqs,\n\u001b[32m    252\u001b[39m         state_steps,\n\u001b[32m    253\u001b[39m         amsgrad=group[\u001b[33m\"\u001b[39m\u001b[33mamsgrad\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    254\u001b[39m         has_complex=has_complex,\n\u001b[32m    255\u001b[39m         beta1=beta1,\n\u001b[32m    256\u001b[39m         beta2=beta2,\n\u001b[32m    257\u001b[39m         lr=group[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    258\u001b[39m         weight_decay=group[\u001b[33m\"\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    259\u001b[39m         eps=group[\u001b[33m\"\u001b[39m\u001b[33meps\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    260\u001b[39m         maximize=group[\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    261\u001b[39m         foreach=group[\u001b[33m\"\u001b[39m\u001b[33mforeach\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    262\u001b[39m         capturable=group[\u001b[33m\"\u001b[39m\u001b[33mcapturable\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    263\u001b[39m         differentiable=group[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    264\u001b[39m         fused=group[\u001b[33m\"\u001b[39m\u001b[33mfused\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    265\u001b[39m         grad_scale=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgrad_scale\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    266\u001b[39m         found_inf=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfound_inf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    267\u001b[39m         decoupled_weight_decay=group[\u001b[33m\"\u001b[39m\u001b[33mdecoupled_weight_decay\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m func(\n\u001b[32m    934\u001b[39m     params,\n\u001b[32m    935\u001b[39m     grads,\n\u001b[32m    936\u001b[39m     exp_avgs,\n\u001b[32m    937\u001b[39m     exp_avg_sqs,\n\u001b[32m    938\u001b[39m     max_exp_avg_sqs,\n\u001b[32m    939\u001b[39m     state_steps,\n\u001b[32m    940\u001b[39m     amsgrad=amsgrad,\n\u001b[32m    941\u001b[39m     has_complex=has_complex,\n\u001b[32m    942\u001b[39m     beta1=beta1,\n\u001b[32m    943\u001b[39m     beta2=beta2,\n\u001b[32m    944\u001b[39m     lr=lr,\n\u001b[32m    945\u001b[39m     weight_decay=weight_decay,\n\u001b[32m    946\u001b[39m     eps=eps,\n\u001b[32m    947\u001b[39m     maximize=maximize,\n\u001b[32m    948\u001b[39m     capturable=capturable,\n\u001b[32m    949\u001b[39m     differentiable=differentiable,\n\u001b[32m    950\u001b[39m     grad_scale=grad_scale,\n\u001b[32m    951\u001b[39m     found_inf=found_inf,\n\u001b[32m    952\u001b[39m     decoupled_weight_decay=decoupled_weight_decay,\n\u001b[32m    953\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/optim/adam.py:456\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    454\u001b[39m         exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[32m    459\u001b[39m     step = step_t\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.train(num_episodes = 1000, logger = logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
